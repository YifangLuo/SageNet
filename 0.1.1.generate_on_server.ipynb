{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']= 'TRUE'\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "from tqdm import tqdm\n",
    "import global_param; reload(global_param)\n",
    "from global_param import *\n",
    "import functions; reload(functions)\n",
    "from functions import int_FD, solve_SGWB\n",
    "\n",
    "import LCDM_stiff_Neff; reload(LCDM_stiff_Neff)\n",
    "from LCDM_stiff_Neff import LCDM_SN as sn\n",
    "\n",
    "import stiff_SGWB; reload(stiff_SGWB)\n",
    "from stiff_SGWB import LCDM_SG as sg\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "volume = 0\n",
    "\n",
    "\n",
    "with open(f'data_part_{volume}.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 过滤出未处理的文档（可能需要根据实际导出的JSON结构调整条件）\n",
    "# 注意：导出的JSON中字段可能与MongoDB中的格式略有不同（如_id是字典）\n",
    "unprocessed_data = [\n",
    "    doc for doc in data \n",
    "    if 'log10OmegaGW' not in doc  # 如果导出时已过滤，可跳过此步\n",
    "]\n",
    "\n",
    "# # 随机抽样（可选，根据需求调整数量）\n",
    "# sample_size = 2500\n",
    "# sampled_data = random.sample(unprocessed_data, min(sample_size, len(unprocessed_data)))\n",
    "\n",
    "# 处理每个文档\n",
    "processed_docs = []\n",
    "for document in tqdm(unprocessed_data):\n",
    "    # 从document中提取参数\n",
    "    r = document['r']\n",
    "    n_t = document['n_t']\n",
    "    T_re = document['T_re']\n",
    "    DN_re = document['DN_re']\n",
    "    kappa10 = document['kappa10']\n",
    "    print(document['_id'])\n",
    "    # 原有计算逻辑（保持不变）\n",
    "    model4_new = sg(r=r, n_t=n_t, cr=0, T_re=T_re, DN_re=DN_re, kappa10=kappa10)\n",
    "    model4_new.SGWB_iter()\n",
    "    N_hc_arr_new = np.array(model4_new.N_hc, dtype=object)\n",
    "    Th_arr_new = np.array(model4_new.Th, dtype=object)\n",
    "    targets_new = [line[-1] for line in Th_arr_new]\n",
    "    windows_new = [[line[0], line[-1]] for line in N_hc_arr_new]\n",
    "    # clear_output()\n",
    "    # 更新文档字段\n",
    "    document.update({\n",
    "        \"targets\": targets_new,\n",
    "        \"windows\": windows_new,\n",
    "        \"f\": list(model4_new.f),\n",
    "        \"log10OmegaGW\": list(model4_new.log10OmegaGW),\n",
    "    })\n",
    "    processed_docs.append(document)\n",
    "\n",
    "# 保存处理后的结果到新文件\n",
    "with open(f'processed_data_{volume}.json', 'w') as f:\n",
    "    json.dump(processed_docs, f, indent=2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e73fff3054a612d1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
