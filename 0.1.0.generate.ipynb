{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-04T09:14:09.982938500Z",
     "start_time": "2025-03-04T09:14:02.273891200Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from bson import ObjectId\n",
    "from importlib import reload\n",
    "import global_param; reload(global_param)\n",
    "import functions; reload(functions)\n",
    "import LCDM_stiff_Neff; reload(LCDM_stiff_Neff)\n",
    "import stiff_SGWB; reload(stiff_SGWB)\n",
    "from stiff_SGWB import LCDM_SG as sg\n",
    "from pyDOE import lhs\n",
    "import pymongo\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']= 'TRUE'\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"solve\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "'''\n",
    "大范围搜索\n",
    "'''\n",
    "def generate_parameters_lhs():\n",
    "    \"\"\"\n",
    "    使用拉丁超立方采样LHS生成参数样本。\n",
    "    参数:\n",
    "        num_samples (int): 需要生成的样本数量\n",
    "    返回:\n",
    "        np.ndarray: 形如 (num_samples, 5) 的数组，列顺序为 [r, n_t, kappa10, T_re, DN_re]\n",
    "    \"\"\"\n",
    "    # 生成LHS样本，范围[0, 1)\n",
    "    # lhs_samples = lhs(5, samples=num_samples, criterion='maximin')\n",
    "    \n",
    "    # 处理每个参数的缩放\n",
    "    # r: 对数缩放 [1e-25, 1]\n",
    "    log_r = np.log10(1e-25) + lhs_samples[:, 0] * (np.log10(1) - np.log10(1e-25))\n",
    "    r = 10 ** log_r\n",
    "    # n_t: 线性缩放 [-1, 6]\n",
    "    n_t = lhs_samples[:, 1] * (6 - (-1)) + (-1)\n",
    "    # kappa10: 对数缩放 [1e-7, 1e3]\n",
    "    log_kappa = np.log10(1e-7) + lhs_samples[:, 2] * (np.log10(1e3) - np.log10(1e-7))\n",
    "    kappa10 = 10 ** log_kappa\n",
    "    # T_re: 对数缩放 [1e-3, 1e7]\n",
    "    log_T = np.log10(1e-3) + lhs_samples[:, 3] * (np.log10(1e7) - np.log10(1e-3))\n",
    "    T_re = 10 ** log_T\n",
    "    # DN_re: 线性缩放 [0, 40]\n",
    "    DN_re = lhs_samples[:, 4] * 40\n",
    "    # 合并参数\n",
    "    return np.column_stack((r, n_t, kappa10, T_re, DN_re))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-01T10:59:15.622938500Z",
     "start_time": "2025-03-01T10:59:15.608719600Z"
    }
   },
   "id": "6d857bb276c6f987"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "lhs_samples = lhs(5, samples=100, criterion='maximin')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-01T09:19:50.138406900Z",
     "start_time": "2025-03-01T09:19:50.060450600Z"
    }
   },
   "id": "f80f3ea3417ce033"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 3571.23it/s]\n"
     ]
    }
   ],
   "source": [
    "collection = db[\"data_test\"]  \n",
    "if __name__ == \"__main__\":\n",
    "    samples = generate_parameters_lhs()\n",
    "    for i in tqdm(samples):\n",
    "        collection.insert_one({\n",
    "            'r':i[0],\n",
    "            'n_t':i[1],\n",
    "            'kappa10':i[2],\n",
    "            'T_re':i[3],\n",
    "            'DN_re':i[4]\n",
    "        })"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-01T09:19:54.292431800Z",
     "start_time": "2025-03-01T09:19:54.227633400Z"
    }
   },
   "id": "70ee2c043337e1d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bson import ObjectId\n",
    "from tqdm import tqdm\n",
    "\n",
    "def Tensor_power(freq,nt):\n",
    "    return 8.315046112484099e-13 * np.power((10**freq)/7.731438287422856e-17, nt)\n",
    "\n",
    "for document in tqdm(collection.find({'f': {'$exists': True}})):\n",
    "    collection.update_one({'_id': ObjectId(document['_id'])}, {'$set': {\n",
    "        'asymp':  list(np.array(document['log10OmegaGW']) - np.log10(Tensor_power(np.array(document['f']),document['n_t'])) + 2 * np.log10(0.6732117) - 2 * np.array(document['f']))\n",
    "    }}, upsert=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc6745ea015a5dd8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reload(stiff_SGWB)\n",
    "import time\n",
    "from stiff_SGWB import LCDM_SG as sg\n",
    "collection = db[\"data_test\"]\n",
    "# 求解示例\n",
    "times = []\n",
    "for document in tqdm(collection.aggregate([{\"$match\":{'log10OmegaGW':{\"$exists\":False}}}])):\n",
    "    try:\n",
    "        r = document['r']\n",
    "        n_t = document['n_t']\n",
    "        T_re = document['T_re']\n",
    "        DN_re = document['DN_re']\n",
    "        kappa10 = document['kappa10']\n",
    "        model4_new = sg(r=r, n_t=n_t, cr=0, T_re=T_re, DN_re=DN_re, kappa10=kappa10)\n",
    "        start = time.time()\n",
    "        model4_new.SGWB_iter()\n",
    "        end = time.time()\n",
    "        times.append(end - start)\n",
    "        N_hc_arr_new = np.array(model4_new.N_hc, dtype=object)\n",
    "        Th_arr_new = np.array(model4_new.Th, dtype=object)\n",
    "        targets_new = [line[-1] for line in Th_arr_new]\n",
    "        windows_new = [[line[0], line[-1]] for line in N_hc_arr_new]\n",
    "        collection.update_one({'_id': ObjectId(document['_id'])}, {'$set': {\n",
    "            \"targets\": targets_new,\n",
    "            \"windows\": windows_new,\n",
    "            \"f\":list(model4_new.f),\n",
    "            \"log10OmegaGW\":list(model4_new.log10OmegaGW),\n",
    "        }}, upsert=True)\n",
    "    except AttributeError:\n",
    "        continue\n",
    "    # collection.insert_one(data_new)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42837387d5d1c7e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[9.261185646057129,\n 16.500418424606323,\n 16.399245500564575,\n 12.206757068634033,\n 9.743135690689087,\n 9.458157539367676,\n 9.62839937210083,\n 9.391486406326294,\n 9.606704473495483,\n 9.68180775642395,\n 21.15862011909485,\n 12.256763219833374,\n 11.303150177001953,\n 9.390976667404175,\n 10.528377771377563]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-01T11:04:22.243360500Z",
     "start_time": "2025-03-01T11:04:22.195788600Z"
    }
   },
   "id": "43f206448ac9350c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15000it [00:08, 1863.80it/s]\n"
     ]
    }
   ],
   "source": [
    "collection = db[\"data3\"]\n",
    "for document in tqdm(collection.aggregate([{\"$match\":{'starts':{\"$exists\":False}}}])):\n",
    "    collection.update_one({'_id': ObjectId(document['_id'])}, {'$set': {\n",
    "        'starts':document['f'][0],\n",
    "        'ends':document['f'][-1]\n",
    "    }}, upsert=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-22T01:13:37.202624800Z",
     "start_time": "2025-02-22T01:13:29.089489200Z"
    }
   },
   "id": "a5d8d9523d260fd"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "with open('total.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "n_servers = 6\n",
    "chunk_size = math.ceil(len(data) / n_servers)\n",
    "\n",
    "for i in range(n_servers):\n",
    "    start = i * chunk_size\n",
    "    end = (i + 1) * chunk_size\n",
    "    chunk = data[start:end]\n",
    "    \n",
    "    with open(f'./databatch/data_part_{i}.json', 'w') as f:\n",
    "        json.dump(chunk, f, indent=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-22T16:43:48.482387800Z",
     "start_time": "2025-02-22T16:43:47.660192600Z"
    }
   },
   "id": "77c778757abfe247"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "小范围扰动\n",
    "'''\n",
    "collection = db[\"macro_2\"]  \n",
    "T_re = 0.19453859\n",
    "DN_re = 39.366618\n",
    "kappa10 = 110.42477\n",
    "perturbation_factor = 0.05\n",
    "num_samples = 10000\n",
    "for _ in tqdm(range(num_samples)):\n",
    "    T_re_new = T_re * (1 + random.uniform(-0.1, 0.1))\n",
    "    DN_re_new = DN_re * (1 + random.uniform(-0.5, 0))\n",
    "    kappa10_new = kappa10 * (1 + random.uniform(-0.5, 0.5))\n",
    "    model4_new = sg(r=3.9585109e-05, n_t=1, cr=0, T_re=T_re_new, DN_re=DN_re_new, kappa10=kappa10_new)\n",
    "    model4_new.SGWB_iter()\n",
    "    N_hc_arr_new = np.array(model4_new.N_hc, dtype=object)\n",
    "    Th_arr_new = np.array(model4_new.Th, dtype=object)\n",
    "    targets_new = [line[-1] for line in Th_arr_new]\n",
    "    windows_new = [[line[0], line[-1]] for line in N_hc_arr_new]\n",
    "    data_new = {\n",
    "        \"targets\": targets_new,\n",
    "        \"windows\": windows_new,\n",
    "        \"f\":list(model4_new.f),\n",
    "        \"log10OmegaGW\":list(model4_new.log10OmegaGW),\n",
    "        \"param\": {    \n",
    "            \"T_re\": T_re_new,\n",
    "            \"DN_re\": DN_re_new,\n",
    "            \"kappa10\": kappa10_new\n",
    "        }\n",
    "    }\n",
    "    clear_output()\n",
    "    collection.insert_one(data_new)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5383f469037a11a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "cache\n",
    "'''\n",
    "reload(stiff_SGWB)\n",
    "from stiff_SGWB import LCDM_SG as sg\n",
    "collection = db[\"param_lhs3\"]\n",
    "# 求解示例\n",
    "for document in tqdm(collection.aggregate([{\"$match\":{'log10OmegaGW':{\"$exists\":False}}}])):\n",
    "    model4_new = sg(r=3.9585109e-05, n_t=1, cr=0, T_re=document['T_re'], DN_re=document['DN_re'], kappa10=document['kappa10'])\n",
    "    model4_new.SGWB_iter()\n",
    "    N_hc_arr_new = np.array(model4_new.N_hc, dtype=object)\n",
    "    Th_arr_new = np.array(model4_new.Th, dtype=object)\n",
    "    targets_new = [line[-1] for line in Th_arr_new]\n",
    "    windows_new = [[line[0], line[-1]] for line in N_hc_arr_new]\n",
    "    clear_output()\n",
    "    collection.update_one({'_id': ObjectId(document['_id'])}, {'$set': {\n",
    "        \"targets\": targets_new,\n",
    "        \"windows\": windows_new,\n",
    "        \"f\":list(model4_new.f),\n",
    "        \"log10OmegaGW\":list(model4_new.log10OmegaGW),\n",
    "    }}, upsert=True)\n",
    "    # collection.insert_one(data_new)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3331031e2463f6e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
